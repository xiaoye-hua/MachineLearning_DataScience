{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_dEaVsqSgNyQ"
   },
   "source": [
    "##### Copyright 2021 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4FyfuZX-gTKS"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sT8AyHRMNh41"
   },
   "source": [
    "# Recommend movies for users with TensorFlow Ranking\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/ranking/tutorials/quickstart\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/ranking/blob/master/docs/tutorials/quickstart.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/ranking/blob/master/docs/tutorials/quickstart.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/ranking/docs/tutorials/quickstart.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8f-reQ11gbLB"
   },
   "source": [
    "In this tutorial, we build a simple two tower ranking model using the [MovieLens 100K dataset](https://grouplens.org/datasets/movielens/100k/) with TF-Ranking. We can use this model to rank and recommend movies for a given user according to their predicted user ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qA00wBE2Ntdm"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Install and import the TF-Ranking library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6yzAaM85Z12D"
   },
   "outputs": [],
   "source": [
    "!pip install -q tensorflow-ranking\n",
    "!pip install -q --upgrade tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n3oYt3R6Nr9l"
   },
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_ranking as tfr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCxQ1CZcO2wh"
   },
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A0sY6-Rtt_Co"
   },
   "source": [
    "Prepare to train a model by creating a ratings dataset and movies dataset. Use `user_id` as the query input feature, `movie_title` as the document input feature, and `user_rating` as the label to train the ranking model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M-mxBYjdO5m7"
   },
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "# Ratings data.\n",
    "ratings = tfds.load('movielens/100k-ratings', split=\"train\")\n",
    "# Features of all the available movies.\n",
    "movies = tfds.load('movielens/100k-movies', split=\"train\")\n",
    "\n",
    "# Select the basic features.\n",
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_title\": x[\"movie_title\"],\n",
    "    \"user_id\": x[\"user_id\"],\n",
    "    \"user_rating\": x[\"user_rating\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gKXEYw6fGikx"
   },
   "outputs": [],
   "source": [
    "# movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JZYJ0wvQGo6C"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5W0HSfmSNCWm"
   },
   "source": [
    "Build vocabularies to convert all user ids and all movie titles into integer indices for embedding layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9I1VTEjHzpfX"
   },
   "outputs": [],
   "source": [
    "movies = movies.map(lambda x: x[\"movie_title\"])\n",
    "users = ratings.map(lambda x: x[\"user_id\"])\n",
    "\n",
    "user_ids_vocabulary = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "    mask_token=None)\n",
    "user_ids_vocabulary.adapt(users.batch(1000))\n",
    "\n",
    "movie_titles_vocabulary = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "    mask_token=None)\n",
    "movie_titles_vocabulary.adapt(movies.batch(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B3wnNK1WG1lP"
   },
   "outputs": [],
   "source": [
    "movie_titles_vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMsmoqWTOTKo"
   },
   "source": [
    "Group by `user_id` to form lists for ranking models:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lXY7kX7nOSwH"
   },
   "outputs": [],
   "source": [
    "key_func = lambda x: user_ids_vocabulary(x[\"user_id\"])\n",
    "reduce_func = lambda key, dataset: dataset.batch(100)\n",
    "ds_train = ratings.group_by_window(\n",
    "    key_func=key_func, reduce_func=reduce_func, window_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "57r87tdQlkcT"
   },
   "outputs": [],
   "source": [
    "for x in ds_train.take(1):\n",
    "  for key, value in x.items():\n",
    "    print(f\"Shape of {key}: {value.shape}\")\n",
    "    print(f\"Example values of {key}: {value[:5].numpy()}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3XV0tcpeIIdj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YcZJf2qxOeWU"
   },
   "source": [
    "Generate batched features and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ctq2RTOqOfAo"
   },
   "outputs": [],
   "source": [
    "def _features_and_labels(\n",
    "    x: Dict[str, tf.Tensor]) -> Tuple[Dict[str, tf.Tensor], tf.Tensor]:\n",
    "  labels = x.pop(\"user_rating\")\n",
    "  return x, labels\n",
    "\n",
    "\n",
    "ds_train = ds_train.map(_features_and_labels)\n",
    "\n",
    "ds_train = ds_train.apply(\n",
    "    tf.data.experimental.dense_to_ragged_batch(batch_size=32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJUU3mv-_VdQ"
   },
   "source": [
    "The `user_id` and `movie_title` tensors generated in `ds_train` are of shape `[32, None]`, where the second dimension is 100 in most cases except for the batches when less than 100 items grouped in lists. A model working on ragged tensors is thus used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GTquqk1GkIfd"
   },
   "outputs": [],
   "source": [
    "for x, label in ds_train.take(1):\n",
    "  for key, value in x.items():\n",
    "    print(f\"Shape of {key}: {value.shape}\")\n",
    "    print(f\"Example values of {key}: {value[:3, :3].numpy()}\")\n",
    "    print()\n",
    "  print(f\"Shape of label: {label.shape}\")\n",
    "  print(f\"Example values of label: {label[:3, :3].numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lrch6rVBOB9Q"
   },
   "source": [
    "## Define a model\n",
    "\n",
    "Define a ranking model by inheriting from `tf.keras.Model` and implementing the `call` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5dNbDZwOIHR"
   },
   "outputs": [],
   "source": [
    "class MovieLensRankingModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, user_vocab, movie_vocab):\n",
    "    super().__init__()\n",
    "\n",
    "    # Set up user and movie vocabulary and embedding.\n",
    "    self.user_vocab = user_vocab\n",
    "    self.movie_vocab = movie_vocab\n",
    "    self.user_embed = tf.keras.layers.Embedding(user_vocab.vocabulary_size(),\n",
    "                                                64)\n",
    "    self.movie_embed = tf.keras.layers.Embedding(movie_vocab.vocabulary_size(),\n",
    "                                                 64)\n",
    "\n",
    "  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
    "    # Define how the ranking scores are computed: \n",
    "    # Take the dot-product of the user embeddings with the movie embeddings.\n",
    "\n",
    "    user_embeddings = self.user_embed(self.user_vocab(features[\"user_id\"]))\n",
    "    movie_embeddings = self.movie_embed(\n",
    "        self.movie_vocab(features[\"movie_title\"]))\n",
    "\n",
    "    return tf.reduce_sum(user_embeddings * movie_embeddings, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMV0HpzmJGWk"
   },
   "source": [
    "Create the model, and then compile it with ranking `tfr.keras.losses` and `tfr.keras.metrics`, which are the core of the TF-Ranking package. \n",
    "\n",
    "This example uses a ranking-specific **softmax loss**, which is a listwise loss introduced to promote all relevant items in the ranking list with better chances on top of the irrelevant ones. In contrast to the softmax loss in the multi-class classification problem, where only one class is positive and the rest are negative, the TF-Ranking library supports multiple relevant documents in a query list and non-binary relevance labels.\n",
    "\n",
    "For ranking metrics, this example uses in specific **Normalized Discounted Cumulative Gain (NDCG)** and **Mean Reciprocal Rank (MRR)**, which calculate the user utility of a ranked query list with position discounts. For more details about ranking metrics, review evaluation measures [offline metrics](https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Offline_metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m6G2OXS_KuQl"
   },
   "outputs": [],
   "source": [
    "dir(tfr.keras.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MySe0JqBMX0J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point-wise loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83BiHSAxL07s"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "loss = tfr.keras.losses.MeanSquaredLoss(ragged=True)\n",
    "\n",
    "\n",
    "model = MovieLensRankingModel(user_ids_vocabulary, movie_titles_vocabulary)\n",
    "optimizer = tf.keras.optimizers.Adagrad(0.5)\n",
    "eval_metrics = [\n",
    "    tfr.keras.metrics.get(key=\"ndcg\", name=\"metric/ndcg\", ragged=True),\n",
    "    tfr.keras.metrics.get(key=\"mrr\", name=\"metric/mrr\", ragged=True)\n",
    "]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=eval_metrics)\n",
    "model.fit(ds_train, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pair-wise loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JZe-WXeVMI0R"
   },
   "outputs": [],
   "source": [
    "# Create the ranking model, trained with a ranking loss and evaluated with\n",
    "# ranking metrics.\n",
    "\n",
    "loss = tfr.keras.losses.PairwiseHingeLoss(ragged=True)\n",
    "\n",
    "\n",
    "model = MovieLensRankingModel(user_ids_vocabulary, movie_titles_vocabulary)\n",
    "optimizer = tf.keras.optimizers.Adagrad(0.5)\n",
    "eval_metrics = [\n",
    "    tfr.keras.metrics.get(key=\"ndcg\", name=\"metric/ndcg\", ragged=True),\n",
    "    tfr.keras.metrics.get(key=\"mrr\", name=\"metric/mrr\", ragged=True)\n",
    "]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=eval_metrics)\n",
    "model.fit(ds_train, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List-wise loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2tQDhqkOKf1"
   },
   "outputs": [],
   "source": [
    "# Create the ranking model, trained with a ranking loss and evaluated with\n",
    "# ranking metrics.\n",
    "\n",
    "loss = tfr.keras.losses.get(\n",
    "    loss=tfr.keras.losses.RankingLossKey.SOFTMAX_LOSS, ragged=True)\n",
    "\n",
    "model = MovieLensRankingModel(user_ids_vocabulary, movie_titles_vocabulary)\n",
    "optimizer = tf.keras.optimizers.Adagrad(0.5)\n",
    "eval_metrics = [\n",
    "    tfr.keras.metrics.get(key=\"ndcg\", name=\"metric/ndcg\", ragged=True),\n",
    "    tfr.keras.metrics.get(key=\"mrr\", name=\"metric/mrr\", ragged=True)\n",
    "]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=eval_metrics)\n",
    "model.fit(ds_train, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeBnBFMfVLzP"
   },
   "source": [
    "## Train and evaluate the model\n",
    "\n",
    "Train the model with `model.fit`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5uuSRXZoOKW"
   },
   "source": [
    "Generate predictions and evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Hryvj3cPnvK"
   },
   "outputs": [],
   "source": [
    "# Get movie title candidate list.\n",
    "for movie_titles in movies.batch(2000):\n",
    "  break\n",
    "\n",
    "# Generate the input for user 42.\n",
    "inputs = {\n",
    "    \"user_id\":\n",
    "        tf.expand_dims(tf.repeat(\"42\", repeats=movie_titles.shape[0]), axis=0),\n",
    "    \"movie_title\":\n",
    "        tf.expand_dims(movie_titles, axis=0)\n",
    "}\n",
    "\n",
    "# Get movie recommendations for user 42.\n",
    "scores = model(inputs)\n",
    "titles = tfr.utils.sort_by_scores(scores,\n",
    "                                  [tf.expand_dims(movie_titles, axis=0)])[0]\n",
    "print(f\"Top 5 recommendations for user 42: {titles[0, :5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "erdwpzZlMw5i"
   },
   "source": [
    "# Ranking pipeline example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to [github page](https://github.com/tensorflow/ranking/blob/master/tensorflow_ranking/examples/tf_ranking_canned_dnn.py) for more details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_ranking'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-32b61189987a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_ranking\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m flags.DEFINE_string(\"train_input_pattern\", None,\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_ranking'"
     ]
    }
   ],
   "source": [
    "# Copyright 2022 The TensorFlow Ranking Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "r\"\"\"TF-Ranking example code for training a canned DNN estimator.\n",
    "\n",
    "The supported proto formats are listed at ../python/data.py.\n",
    "--------------------------------------------------------------------------------\n",
    "Sample command lines:\n",
    "\n",
    "MODEL_DIR=/tmp/output && \\\n",
    "TRAIN=tensorflow_ranking/examples/data/train_numerical_elwc.tfrecord && \\\n",
    "EVAL=tensorflow_ranking/examples/data/vali_numerical_elwc.tfrecord && \\\n",
    "rm -rf $MODEL_DIR && \\\n",
    "bazel build -c opt \\\n",
    "tensorflow_ranking/examples/tf_ranking_canned_dnn_py_binary && \\\n",
    "./bazel-bin/tensorflow_ranking/examples/tf_ranking_canned_dnn_py_binary \\\n",
    "--train_input_pattern=$TRAIN \\\n",
    "--eval_input_pattern=$EVAL \\\n",
    "--model_dir=$MODEL_DIR\n",
    "\n",
    "You can use TensorBoard to display the training results stored in $MODEL_DIR.\n",
    "\n",
    "Notes:\n",
    "  * Use --alsologtostderr if the output is not printed into screen.\n",
    "\"\"\"\n",
    "\n",
    "from absl import flags\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_ranking as tfr\n",
    "\n",
    "flags.DEFINE_string(\"train_input_pattern\", None,\n",
    "                    \"Input file path used for training.\")\n",
    "flags.DEFINE_string(\"eval_input_pattern\", None,\n",
    "                    \"Input file path used for eval.\")\n",
    "flags.DEFINE_string(\"model_dir\", None, \"Output directory for models.\")\n",
    "flags.DEFINE_integer(\"batch_size\", 32, \"The batch size for train.\")\n",
    "flags.DEFINE_integer(\"num_train_steps\", 15000, \"Number of steps for train.\")\n",
    "flags.DEFINE_integer(\"num_eval_steps\", 10, \"Number of steps for evaluation.\")\n",
    "flags.DEFINE_integer(\"checkpoint_secs\", 30,\n",
    "                     \"Saves a model checkpoint every checkpoint_secs seconds.\")\n",
    "flags.DEFINE_integer(\"num_checkpoints\", 100,\n",
    "                     \"Saves at most num_checkpoints checkpoints in workspace.\")\n",
    "flags.DEFINE_integer(\"num_features\", 136, \"Number of features per example.\")\n",
    "flags.DEFINE_integer(\n",
    "    \"list_size\", 100,\n",
    "    \"List size used for training. Use None for dynamic list size.\")\n",
    "flags.DEFINE_float(\"learning_rate\", 0.05, \"Learning rate for optimizer.\")\n",
    "flags.DEFINE_float(\"dropout\", 0.8, \"The dropout rate before output layer.\")\n",
    "flags.DEFINE_list(\"hidden_layer_dims\", [\"64\", \"32\", \"16\"],\n",
    "                  \"Sizes for hidden layers.\")\n",
    "flags.DEFINE_string(\"loss\", \"approx_ndcg_loss\",\n",
    "                    \"The RankingLossKey for the loss function.\")\n",
    "flags.DEFINE_bool(\"convert_labels_to_binary\", False,\n",
    "                  \"If true, relevance labels are set to either 0 or 1.\")\n",
    "flags.DEFINE_bool(\"listwise_inference\", False,\n",
    "                  \"If true, exports accept `data_format` while serving.\")\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "_LABEL_FEATURE = \"utility\"\n",
    "\n",
    "\n",
    "def context_feature_columns():\n",
    "  \"\"\"Returns context feature columns.\"\"\"\n",
    "  return {}\n",
    "\n",
    "\n",
    "def example_feature_columns():\n",
    "  \"\"\"Returns the example feature columns.\"\"\"\n",
    "  feature_names = [\n",
    "      \"custom_features_{}\".format(i + 1) for i in range(FLAGS.num_features)\n",
    "  ]\n",
    "  return {\n",
    "      name:\n",
    "      tf.feature_column.numeric_column(name, shape=(1,), default_value=0.0)\n",
    "      for name in feature_names\n",
    "  }\n",
    "\n",
    "\n",
    "def train_and_eval():\n",
    "  \"\"\"Train and Evaluate.\"\"\"\n",
    "  optimizer = tf.compat.v1.train.AdagradOptimizer(\n",
    "      learning_rate=FLAGS.learning_rate)\n",
    "\n",
    "  estimator = tfr.estimator.make_dnn_ranking_estimator(\n",
    "      example_feature_columns(),\n",
    "      FLAGS.hidden_layer_dims,\n",
    "      context_feature_columns=context_feature_columns(),\n",
    "      optimizer=optimizer,\n",
    "      learning_rate=FLAGS.learning_rate,\n",
    "      loss=FLAGS.loss,\n",
    "      loss_reduction=tf.compat.v1.losses.Reduction.SUM_OVER_BATCH_SIZE,\n",
    "      activation_fn=tf.nn.relu,\n",
    "      dropout=FLAGS.dropout,\n",
    "      use_batch_norm=True,\n",
    "      model_dir=FLAGS.model_dir)\n",
    "\n",
    "  hparams = {\"train_input_pattern\": FLAGS.train_input_pattern,\n",
    "             \"eval_input_pattern\": FLAGS.eval_input_pattern,\n",
    "             \"learning_rate\": FLAGS.learning_rate,\n",
    "             \"train_batch_size\": FLAGS.batch_size,\n",
    "             \"eval_batch_size\": FLAGS.batch_size,\n",
    "             \"predict_batch_size\": FLAGS.batch_size,\n",
    "             \"num_train_steps\": FLAGS.num_train_steps,\n",
    "             \"num_eval_steps\": FLAGS.num_eval_steps,\n",
    "             \"checkpoint_secs\": FLAGS.checkpoint_secs,\n",
    "             \"num_checkpoints\": FLAGS.num_checkpoints,\n",
    "             \"loss\": FLAGS.loss,\n",
    "             \"list_size\": FLAGS.list_size,\n",
    "             \"convert_labels_to_binary\": FLAGS.convert_labels_to_binary,\n",
    "             \"listwise_inference\": FLAGS.listwise_inference,\n",
    "             \"model_dir\": FLAGS.model_dir}\n",
    "\n",
    "  ranking_pipeline = tfr.ext.pipeline.RankingPipeline(\n",
    "      context_feature_columns(),\n",
    "      example_feature_columns(),\n",
    "      hparams,\n",
    "      estimator=estimator,\n",
    "      label_feature_name=_LABEL_FEATURE,\n",
    "      label_feature_type=tf.int64)\n",
    "\n",
    "  ranking_pipeline.train_and_eval()\n",
    "\n",
    "\n",
    "def main(_):\n",
    "  tf.compat.v1.set_random_seed(1234)\n",
    "  tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
    "  train_and_eval()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  flags.mark_flag_as_required(\"train_input_pattern\")\n",
    "  flags.mark_flag_as_required(\"eval_input_pattern\")\n",
    "  flags.mark_flag_as_required(\"model_dir\")\n",
    "\n",
    "  tf.compat.v1.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 The TensorFlow Ranking Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"Tests for tf_ranking_canned_dnn.py.\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "from absl import flags\n",
    "from absl.testing import flagsaver\n",
    "from absl.testing import parameterized\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from google.protobuf import text_format\n",
    "from tensorflow_ranking.examples import tf_ranking_canned_dnn\n",
    "from tensorflow_serving.apis import input_pb2\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "ELWC = text_format.Parse(\n",
    "    \"\"\"\n",
    "    context {\n",
    "    }\n",
    "    examples {\n",
    "      features {\n",
    "        feature {\n",
    "          key: \"custom_features_1\"\n",
    "          value { float_list { value: 1.0 } }\n",
    "        }\n",
    "        feature {\n",
    "          key: \"custom_features_2\"\n",
    "          value { float_list { value: 1.5 } }\n",
    "        }\n",
    "        feature {\n",
    "          key: \"utility\"\n",
    "          value { int64_list { value: 1 } }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    examples {\n",
    "      features {\n",
    "        feature {\n",
    "          key: \"custom_features_1\"\n",
    "          value { float_list { value: 1.0 } }\n",
    "        }\n",
    "        feature {\n",
    "          key: \"custom_features_3\"\n",
    "          value { float_list { value: 2.1 } }\n",
    "        }\n",
    "        feature {\n",
    "          key: \"utility\"\n",
    "          value { int64_list { value: 0 } }\n",
    "        }\n",
    "      }\n",
    "    }\"\"\", input_pb2.ExampleListWithContext())\n",
    "\n",
    "\n",
    "def _write_tfrecord_files(path):\n",
    "  elwc_list = [ELWC.SerializeToString()] * 10\n",
    "  if tf.io.gfile.exists(path):\n",
    "    tf.io.gfile.remove(path)\n",
    "\n",
    "  with tf.io.TFRecordWriter(path) as writer:\n",
    "    for elwc in elwc_list:\n",
    "      writer.write(elwc)\n",
    "\n",
    "\n",
    "class TFRankingCannedDNNTest(tf.test.TestCase, parameterized.TestCase):\n",
    "\n",
    "  def setUp(self):\n",
    "    super(TFRankingCannedDNNTest, self).setUp()\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "\n",
    "    # Prepares model directory, and train and eval data.\n",
    "    self._base_model_dir = tf.compat.v1.test.get_temp_dir() + \"/model/\"\n",
    "    tf.io.gfile.makedirs(self._base_model_dir)\n",
    "    self._data_file = os.path.join(self._base_model_dir, \"elwc.tfrecord\")\n",
    "    _write_tfrecord_files(self._data_file)\n",
    "\n",
    "  def tearDown(self):\n",
    "    super(TFRankingCannedDNNTest, self).tearDown()\n",
    "    if self._base_model_dir:\n",
    "      tf.io.gfile.rmtree(self._base_model_dir)\n",
    "    self._base_model_dir = None\n",
    "\n",
    "  @parameterized.named_parameters((\"enable_listwise_inference\", True),\n",
    "                                  (\"disable_listwise_inference\", False))\n",
    "  def test_train_and_eval(self, listwise_inference):\n",
    "    self._model_dir = self._base_model_dir + \"/\" + str(listwise_inference)\n",
    "    with flagsaver.flagsaver(\n",
    "        train_input_pattern=self._data_file,\n",
    "        eval_input_pattern=self._data_file,\n",
    "        model_dir=self._model_dir,\n",
    "        num_features=3,\n",
    "        num_train_steps=10,\n",
    "        listwise_inference=listwise_inference):\n",
    "      tf_ranking_canned_dnn.train_and_eval()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  tf.test.main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python3.6(machine_learning_learning)",
   "language": "python",
   "name": "machine_learning_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
