{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.datasets import load_iris, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 2\n",
    "random_state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(\n",
    "    max_depth=max_depth,\n",
    "    random_state=random_state,\n",
    "#     criterion=\"gini\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9066666666666666"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(\n",
    "    max_depth=max_depth,\n",
    "    random_state=random_state,\n",
    "#     criterion=\"gini\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8996773794824336"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Catch-up "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import logging\n",
    "base_dir = '../'\n",
    "sys.path.append(base_dir)\n",
    "# from src.Model.Recommender.DNN import DNN\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "from src.BaseClass.DLModel import DLModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Model config\n",
    "hidden_dim_lst = [96, 24, 8]\n",
    "position_dnn_dims = [24, 3]\n",
    "# feature_dim = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_eval, y_train, y_eval = train_test_split(X_train, y_train, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30) (114, 30)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{X_train.shape} {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean radius                0\n",
       "mean texture               0\n",
       "mean perimeter             0\n",
       "mean area                  0\n",
       "mean smoothness            0\n",
       "mean compactness           0\n",
       "mean concavity             0\n",
       "mean concave points        0\n",
       "mean symmetry              0\n",
       "mean fractal dimension     0\n",
       "radius error               0\n",
       "texture error              0\n",
       "perimeter error            0\n",
       "area error                 0\n",
       "smoothness error           0\n",
       "compactness error          0\n",
       "concavity error            0\n",
       "concave points error       0\n",
       "symmetry error             0\n",
       "fractal dimension error    0\n",
       "worst radius               0\n",
       "worst texture              0\n",
       "worst perimeter            0\n",
       "worst area                 0\n",
       "worst smoothness           0\n",
       "worst compactness          0\n",
       "worst concavity            0\n",
       "worst concave points       0\n",
       "worst symmetry             0\n",
       "worst fractal dimension    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>11.26</td>\n",
       "      <td>19.83</td>\n",
       "      <td>71.30</td>\n",
       "      <td>388.1</td>\n",
       "      <td>0.08511</td>\n",
       "      <td>0.04413</td>\n",
       "      <td>0.005067</td>\n",
       "      <td>0.005664</td>\n",
       "      <td>0.1637</td>\n",
       "      <td>0.06343</td>\n",
       "      <td>...</td>\n",
       "      <td>11.93</td>\n",
       "      <td>26.43</td>\n",
       "      <td>76.38</td>\n",
       "      <td>435.9</td>\n",
       "      <td>0.11080</td>\n",
       "      <td>0.07723</td>\n",
       "      <td>0.02533</td>\n",
       "      <td>0.02832</td>\n",
       "      <td>0.2557</td>\n",
       "      <td>0.07613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>12.23</td>\n",
       "      <td>19.56</td>\n",
       "      <td>78.54</td>\n",
       "      <td>461.0</td>\n",
       "      <td>0.09586</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>0.041870</td>\n",
       "      <td>0.041070</td>\n",
       "      <td>0.1979</td>\n",
       "      <td>0.06013</td>\n",
       "      <td>...</td>\n",
       "      <td>14.44</td>\n",
       "      <td>28.36</td>\n",
       "      <td>92.15</td>\n",
       "      <td>638.4</td>\n",
       "      <td>0.14290</td>\n",
       "      <td>0.20420</td>\n",
       "      <td>0.13770</td>\n",
       "      <td>0.10800</td>\n",
       "      <td>0.2668</td>\n",
       "      <td>0.08174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>16.65</td>\n",
       "      <td>21.38</td>\n",
       "      <td>110.00</td>\n",
       "      <td>904.6</td>\n",
       "      <td>0.11210</td>\n",
       "      <td>0.14570</td>\n",
       "      <td>0.152500</td>\n",
       "      <td>0.091700</td>\n",
       "      <td>0.1995</td>\n",
       "      <td>0.06330</td>\n",
       "      <td>...</td>\n",
       "      <td>26.46</td>\n",
       "      <td>31.56</td>\n",
       "      <td>177.00</td>\n",
       "      <td>2215.0</td>\n",
       "      <td>0.18050</td>\n",
       "      <td>0.35780</td>\n",
       "      <td>0.46950</td>\n",
       "      <td>0.20950</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.09564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>20.26</td>\n",
       "      <td>23.03</td>\n",
       "      <td>132.40</td>\n",
       "      <td>1264.0</td>\n",
       "      <td>0.09078</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.146500</td>\n",
       "      <td>0.086830</td>\n",
       "      <td>0.2095</td>\n",
       "      <td>0.05649</td>\n",
       "      <td>...</td>\n",
       "      <td>24.22</td>\n",
       "      <td>31.59</td>\n",
       "      <td>156.10</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>0.11900</td>\n",
       "      <td>0.35390</td>\n",
       "      <td>0.40980</td>\n",
       "      <td>0.15730</td>\n",
       "      <td>0.3689</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>12.80</td>\n",
       "      <td>17.46</td>\n",
       "      <td>83.05</td>\n",
       "      <td>508.3</td>\n",
       "      <td>0.08044</td>\n",
       "      <td>0.08895</td>\n",
       "      <td>0.073900</td>\n",
       "      <td>0.040830</td>\n",
       "      <td>0.1574</td>\n",
       "      <td>0.05750</td>\n",
       "      <td>...</td>\n",
       "      <td>13.74</td>\n",
       "      <td>21.06</td>\n",
       "      <td>90.72</td>\n",
       "      <td>591.0</td>\n",
       "      <td>0.09534</td>\n",
       "      <td>0.18120</td>\n",
       "      <td>0.19010</td>\n",
       "      <td>0.08296</td>\n",
       "      <td>0.1988</td>\n",
       "      <td>0.07053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "522        11.26         19.83           71.30      388.1          0.08511   \n",
       "200        12.23         19.56           78.54      461.0          0.09586   \n",
       "24         16.65         21.38          110.00      904.6          0.11210   \n",
       "95         20.26         23.03          132.40     1264.0          0.09078   \n",
       "397        12.80         17.46           83.05      508.3          0.08044   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "522           0.04413        0.005067             0.005664         0.1637   \n",
       "200           0.08087        0.041870             0.041070         0.1979   \n",
       "24            0.14570        0.152500             0.091700         0.1995   \n",
       "95            0.13130        0.146500             0.086830         0.2095   \n",
       "397           0.08895        0.073900             0.040830         0.1574   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "522                 0.06343  ...         11.93          26.43   \n",
       "200                 0.06013  ...         14.44          28.36   \n",
       "24                  0.06330  ...         26.46          31.56   \n",
       "95                  0.05649  ...         24.22          31.59   \n",
       "397                 0.05750  ...         13.74          21.06   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "522            76.38       435.9           0.11080            0.07723   \n",
       "200            92.15       638.4           0.14290            0.20420   \n",
       "24            177.00      2215.0           0.18050            0.35780   \n",
       "95            156.10      1750.0           0.11900            0.35390   \n",
       "397            90.72       591.0           0.09534            0.18120   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "522          0.02533               0.02832          0.2557   \n",
       "200          0.13770               0.10800          0.2668   \n",
       "24           0.46950               0.20950          0.3613   \n",
       "95           0.40980               0.15730          0.3689   \n",
       "397          0.19010               0.08296          0.1988   \n",
       "\n",
       "     worst fractal dimension  \n",
       "522                  0.07613  \n",
       "200                  0.08174  \n",
       "24                   0.09564  \n",
       "95                   0.08368  \n",
       "397                  0.07053  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# help(train_test_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNN(hidden_dim=hidden_dim_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<src.Model.Recommender.DNN.DNN at 0x7fa911384e80>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(Model):\n",
    "    def __init__(self, hidden_dim: List[int], sigmoid=True) -> None:\n",
    "        super(DNN, self).__init__()\n",
    "        for dim in hidden_dim:\n",
    "            self.layers_lst.append(\n",
    "                Dense(units=dim, use_bias=True)\n",
    "            )\n",
    "        self.sigmoid = sigmoid\n",
    "        if self.sigmoid:\n",
    "            self.layers_lst.append(\n",
    "                Activation(activation=\"sigmoid\")\n",
    "            )\n",
    "            \n",
    "    def call(self, inputs, training=False, mask=None):\n",
    "        print(inputs.shape)\n",
    "        for layer in self.layers_lst:\n",
    "            inputs = layer(inputs)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam'\n",
    "    , loss=tf.keras.losses.BinaryCrossentropy(\n",
    "#         from_logits=True\n",
    "    )\n",
    "    , metrics=[\n",
    "        tf.keras.metrics.AUC(), \n",
    "#                tf.keras.losses.BinaryCrossentropy()\n",
    "    ]\n",
    ")\n",
    "model.fit(\n",
    "    x=np.asarray(X_train)\n",
    "    , y=np.asarray(y_train)\n",
    "#     , batch=3\n",
    "    , epochs=6\n",
    "    , validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 409 samples, validate on 46 samples\n",
      "Epoch 1/6\n",
      "409/409 [==============================] - 2s 4ms/sample - loss: 2.9213 - auc_11: 0.8142 - val_loss: 0.4211 - val_auc_11: 0.9733\n",
      "Epoch 2/6\n",
      "409/409 [==============================] - 0s 208us/sample - loss: 1.5985 - auc_11: 0.8968 - val_loss: 0.6233 - val_auc_11: 0.9524\n",
      "Epoch 3/6\n",
      "409/409 [==============================] - 0s 221us/sample - loss: 0.8807 - auc_11: 0.9395 - val_loss: 0.4869 - val_auc_11: 0.9524\n",
      "Epoch 4/6\n",
      "409/409 [==============================] - 0s 217us/sample - loss: 0.6941 - auc_11: 0.9461 - val_loss: 0.2597 - val_auc_11: 0.9752\n",
      "Epoch 5/6\n",
      "409/409 [==============================] - 0s 213us/sample - loss: 0.6051 - auc_11: 0.9568 - val_loss: 0.3596 - val_auc_11: 0.9762\n",
      "Epoch 6/6\n",
      "409/409 [==============================] - 0s 230us/sample - loss: 0.6183 - auc_11: 0.9396 - val_loss: 0.1539 - val_auc_11: 0.9752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa9110cec88>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5717250291715589, 0.9410291]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=np.asarray(X_test), y=np.asarray(y_test), verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tags = 12  # Number of unique issue tags\n",
    "num_words = 10000  # Size of vocabulary obtained when preprocessing text data\n",
    "num_departments = 4  # Number of departments for predictions\n",
    "\n",
    "title_input = keras.Input(\n",
    "    shape=(None,), name=\"title\"\n",
    ")  # Variable-length sequence of ints\n",
    "body_input = keras.Input(shape=(None,), name=\"body\")  # Variable-length sequence of ints\n",
    "tags_input = keras.Input(\n",
    "    shape=(num_tags,), name=\"tags\"\n",
    ")  # Binary vectors of size `num_tags`\n",
    "\n",
    "# Embed each word in the title into a 64-dimensional vector\n",
    "title_features = layers.Embedding(num_words, 64)(title_input)\n",
    "# Embed each word in the text into a 64-dimensional vector\n",
    "body_features = layers.Embedding(num_words, 64)(body_input)\n",
    "\n",
    "# Reduce sequence of embedded words in the title into a single 128-dimensional vector\n",
    "title_features = layers.LSTM(128)(title_features)\n",
    "# Reduce sequence of embedded words in the body into a single 32-dimensional vector\n",
    "body_features = layers.LSTM(32)(body_features)\n",
    "\n",
    "# Merge all available features into a single large vector via concatenation\n",
    "x = layers.concatenate([title_features, body_features, tags_input])\n",
    "\n",
    "# Stick a logistic regression for priority prediction on top of the features\n",
    "priority_pred = layers.Dense(1, name=\"priority\")(x)\n",
    "# Stick a department classifier on top of the features\n",
    "department_pred = layers.Dense(num_departments, name=\"department\")(x)\n",
    "\n",
    "# Instantiate an end-to-end model predicting both priority and department\n",
    "model = keras.Model(\n",
    "    inputs=[title_input, body_input, tags_input],\n",
    "    outputs=[priority_pred, department_pred],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.utils.plot_model(model, \"multi_input_and_output_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss={\n",
    "        \"priority\": keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "        \"department\": keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    },\n",
    "    loss_weights={\"priority\": 1.0, \"department\": 0.2},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1280 samples\n",
      "Epoch 1/2\n",
      "1280/1280 [==============================] - 13s 11ms/sample - loss: 1.3291 - priority_loss: 0.6991 - department_loss: 3.1501\n",
      "Epoch 2/2\n",
      "1280/1280 [==============================] - 8s 6ms/sample - loss: 1.3065 - priority_loss: 0.6970 - department_loss: 3.0473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa9166bb7f0>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummy input data\n",
    "title_data = np.random.randint(num_words, size=(1280, 10))\n",
    "body_data = np.random.randint(num_words, size=(1280, 100))\n",
    "tags_data = np.random.randint(2, size=(1280, num_tags)).astype(\"float32\")\n",
    "\n",
    "# Dummy target data\n",
    "priority_targets = np.random.random(size=(1280, 1))\n",
    "dept_targets = np.random.randint(2, size=(1280, num_departments))\n",
    "\n",
    "model.fit(\n",
    "    {\"title\": title_data, \"body\": body_data, \"tags\": tags_data},\n",
    "    {\"priority\": priority_targets, \"department\": dept_targets},\n",
    "    epochs=2,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2954461485147477, 0.6945294, 3.0045838]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(\n",
    "    {\"title\": title_data, \"body\": body_data, \"tags\": tags_data},\n",
    "    {\"priority\": priority_targets, \"department\": dept_targets},\n",
    "verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "priority, department = model.predict({\"title\": title_data, \"body\": body_data, \"tags\": tags_data},)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 1)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priority.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 4)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "department.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My own codes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DNN(DLModel):\n",
    "#     def __init__(self, hidden_dim: List[int], sigmoid=True) -> None:\n",
    "#         super(DNN, self).__init__()\n",
    "#         for dim in hidden_dim:\n",
    "#             self.layers_lst.append(\n",
    "#                 Dense(units=dim, use_bias=True)\n",
    "#             )\n",
    "#         self.sigmoid = sigmoid\n",
    "#         if self.sigmoid:\n",
    "#             self.layers_lst.append(\n",
    "#                 Activation(activation=\"sigmoid\")\n",
    "#             )\n",
    "            \n",
    "#     def call(self, inputs, training=False, mask=None):\n",
    "#         print(inputs.shape)\n",
    "#         for layer in self.layers_lst:\n",
    "#             inputs = layer(inputs)\n",
    "#         return inputs\n",
    "\n",
    "\n",
    "from src.BaseClass.DLModel import DLModel\n",
    "from src.Model.Recommender.DNN import DNN\n",
    "\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dense\n",
    "from typing import List\n",
    "import tensorflow as tf\n",
    "    \n",
    "class DNN_position(DLModel):\n",
    "    def __init__(self, dnn_dims: List[int], position_dnn_dims: List[int], output_dim=1) -> None:\n",
    "        super(DNN_position, self).__init__()\n",
    "        self.dnn = DNN(hidden_dim=dnn_dims, sigmoid=False)\n",
    "        self.position_dnn = DNN(hidden_dim=position_dnn_dims, sigmoid=False)\n",
    "        self.concat = tf.keras.layers.Concatenate()\n",
    "        self.dense = Dense(units=1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs, training=False, mask=None) -> tf.Tensor:\n",
    "        dnn_layer = self.dnn(inputs)\n",
    "        dnn_position_layer = self.position_dnn(inputs)\n",
    "        final_layer = self.concat([dnn_layer, dnn_position_layer])\n",
    "        output = self.dense(final_layer)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[96, 24, 8]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_dim_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNN_position(dnn_dims=hidden_dim_lst, position_dnn_dims=position_dnn_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam'\n",
    "    , loss=tf.keras.losses.BinaryCrossentropy(\n",
    "#         from_logits=True\n",
    "    )\n",
    "    , metrics=[\n",
    "        tf.keras.metrics.AUC(), \n",
    "#                tf.keras.losses.BinaryCrossentropy()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method DNN_position.call of <__main__.DNN_position object at 0x7fa917aa1c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method DNN_position.call of <__main__.DNN_position object at 0x7fa917aa1c50>>, which Python reported as:\n",
      "    def call(self, inputs, training=False, mask=None) -> tf.Tensor:\n",
      "        dnn_layer = self.dnn(inputs)\n",
      "        dnn_position_layer = self.position_dnn(inputs)\n",
      "#         if training:\n",
      "        final_layer = self.concat([dnn_layer, dnn_position_layer])\n",
      "        output = self.dense(final_layer)\n",
      "        return output\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING: Entity <bound method DNN_position.call of <__main__.DNN_position object at 0x7fa917aa1c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method DNN_position.call of <__main__.DNN_position object at 0x7fa917aa1c50>>, which Python reported as:\n",
      "    def call(self, inputs, training=False, mask=None) -> tf.Tensor:\n",
      "        dnn_layer = self.dnn(inputs)\n",
      "        dnn_position_layer = self.position_dnn(inputs)\n",
      "#         if training:\n",
      "        final_layer = self.concat([dnn_layer, dnn_position_layer])\n",
      "        output = self.dense(final_layer)\n",
      "        return output\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "Train on 455 samples\n",
      "Epoch 1/6\n",
      "455/455 [==============================] - 2s 3ms/sample - loss: 17.6465 - auc_20: 0.6091\n",
      "Epoch 2/6\n",
      "455/455 [==============================] - 0s 216us/sample - loss: 3.2596 - auc_20: 0.8319\n",
      "Epoch 3/6\n",
      "455/455 [==============================] - 0s 138us/sample - loss: 2.4254 - auc_20: 0.8589\n",
      "Epoch 4/6\n",
      "455/455 [==============================] - 0s 143us/sample - loss: 1.5066 - auc_20: 0.9035\n",
      "Epoch 5/6\n",
      "455/455 [==============================] - 0s 176us/sample - loss: 1.5047 - auc_20: 0.8995\n",
      "Epoch 6/6\n",
      "455/455 [==============================] - 0s 143us/sample - loss: 1.1955 - auc_20: 0.9174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa8eeb23d68>"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=np.asarray(X_train)\n",
    "    , y=np.asarray(y_train)\n",
    "#     , batch=3\n",
    "    , epochs=6\n",
    "#     , validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dnn_position_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dnn_29 (DNN)                 multiple                  5504      \n",
      "_________________________________________________________________\n",
      "dnn_30 (DNN)                 multiple                  819       \n",
      "_________________________________________________________________\n",
      "concatenate_5 (Concatenate)  multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             multiple                  12        \n",
      "=================================================================\n",
      "Total params: 6,335\n",
      "Trainable params: 6,335\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"multi_input_and_output_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9218728791155419, 0.9074508]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=np.asarray(X_test), y=np.asarray(y_test), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python3.6(machine_learning_learning)",
   "language": "python",
   "name": "machine_learning_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
