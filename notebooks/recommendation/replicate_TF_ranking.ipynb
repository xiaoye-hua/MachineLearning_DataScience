{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ff19d72",
   "metadata": {},
   "source": [
    "# Package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "861126e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfd\n",
    "import tensorflow_ranking as tfr\n",
    "from typing import Dict, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efd22df",
   "metadata": {},
   "source": [
    "# Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f6ee7edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1517722",
   "metadata": {},
   "source": [
    "# Data process "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddb7d7d",
   "metadata": {},
   "source": [
    "## Raw data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d6f232d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = tfd.load(name='movielens/100k-ratings', split='train')\n",
    "movies = tfd.load(name='movielens/100k-movies', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f5ba822b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(ratings.take(2).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ad871ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.map( lambda x: {\n",
    "    \"user_id\": x['user_id']\n",
    "    , 'movie_id': x['movie_id']\n",
    "    , 'user_rating': x['user_rating']\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "50cd3646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'user_id': b'138', 'movie_id': b'357', 'user_rating': 4.0},\n",
       " {'user_id': b'92', 'movie_id': b'709', 'user_rating': 2.0}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ratings.take(2).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2b5634bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'movie_genres': array([4]),\n",
       "  'movie_id': b'1681',\n",
       "  'movie_title': b'You So Crazy (1994)'},\n",
       " {'movie_genres': array([4, 7]),\n",
       "  'movie_id': b'1457',\n",
       "  'movie_title': b'Love Is All There Is (1996)'}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(movies.take(2).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4581c32",
   "metadata": {},
   "source": [
    "## Id map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d56f69c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ids = movies.map(lambda x: x['movie_id'])\n",
    "user_ids = ratings.map(lambda x: x['user_id'])\n",
    "\n",
    "movie_vocab = tf.keras.layers.StringLookup()\n",
    "user_vocab = tf.keras.layers.StringLookup()\n",
    "\n",
    "movie_vocab.adapt(movie_ids.batch(batch_size))\n",
    "user_vocab.adapt(user_ids.batch(batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9f7be8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.preprocessing.string_lookup.StringLookup at 0x7ff33565d9e8>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6676d540",
   "metadata": {},
   "source": [
    "## train data -> aggated by user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3bfcbdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_func = lambda x: user_vocab(x['user_id'])\n",
    "reduce_func = lambda key, dataset: dataset.batch(batch_size)\n",
    "window_size = 1000\n",
    "\n",
    "ds_train = ratings.group_by_window(key_func=key_func, reduce_func=reduce_func,\n",
    "                         window_size=window_size\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "db1388e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_label(x: Dict[str, tf.Tensor]) -> Tuple[Dict[str, tf.Tensor], tf.Tensor]:\n",
    "    label = x.pop('user_rating')\n",
    "    return x, label\n",
    "\n",
    "ds_train = ds_train.map(lambda x: get_feature_label(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "01c904b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "531e048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.apply(\n",
    "    tf.data.experimental.dense_to_ragged_batch(batch_size=32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5817627a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of user_id: (32, None)\n",
      "Example values of user_id: [[b'405' b'405' b'405']\n",
      " [b'405' b'405' b'405']\n",
      " [b'405' b'405' b'405']]\n",
      "\n",
      "Shape of movie_id: (32, None)\n",
      "Example values of movie_id: [[b'530' b'98' b'1415']\n",
      " [b'1073' b'1268' b'1091']\n",
      " [b'202' b'1429' b'1308']]\n",
      "\n",
      "Shape of label: (32, None)\n",
      "Example values of label: [[1. 4. 1.]\n",
      " [1. 1. 1.]\n",
      " [4. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "for x, label in ds_train.take(1):\n",
    "  for key, value in x.items():\n",
    "    print(f\"Shape of {key}: {value.shape}\")\n",
    "    print(f\"Example values of {key}: {value[:3, :3].numpy()}\")\n",
    "    print()\n",
    "  print(f\"Shape of label: {label.shape}\")\n",
    "  print(f\"Example values of label: {label[:3, :3].numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b65153",
   "metadata": {},
   "source": [
    "# Model Definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e48592eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.training.Model"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "05fb579a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "944"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_vocab.vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1228433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLenModel(tf.keras.Model):\n",
    "    def __init__(self, user_vocab, movie_vocab):\n",
    "        super().__init__()\n",
    "        embedding_dim = 24\n",
    "        self.user_embedding = tf.keras.layers.Embedding(input_dim=user_vocab.vocabulary_size()\n",
    "                                                       , output_dim=embedding_dim)\n",
    "        self.movie_embedding = tf.keras.layers.Embedding(input_dim=movie_vocab.vocabulary_size()\n",
    "                                                       , output_dim=embedding_dim)\n",
    "        self.user_vocab = user_vocab\n",
    "        self.movie_vocab = movie_vocab\n",
    "    \n",
    "    def call(self, features: Dict[str, tf.Tensor]):\n",
    "        user_emb = self.user_embedding(self.user_vocab(features['user_id']))\n",
    "        movie_emb = self.movie_embedding(self.movie_vocab(features['movie_id']))\n",
    "        score = tf.math.reduce_sum(user_emb*movie_emb, axis=2)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ce282df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MovieLenModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06333a7b",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf883bf",
   "metadata": {},
   "source": [
    "## pointwise loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fa817869",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model1 = MovieLenModel(user_vocab=user_vocab, movie_vocab=movie_vocab)\n",
    "\n",
    "loss = tfr.keras.losses.MeanSquaredLoss(ragged=True)\n",
    "optimizor = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "metrics = [\n",
    "     tfr.keras.metrics.NDCGMetric(ragged=True)\n",
    "    , tfr.keras.metrics.MRRMetric(ragged=True)\n",
    "]\n",
    "\n",
    "model1.compile(loss=loss, optimizer=optimizor, metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3db5c233",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/.conda/envs/machine_learning_learning/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/MeanSquaredLoss/RaggedToTensor_2/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/MeanSquaredLoss/RaggedToTensor_2/boolean_mask/GatherV2:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/MeanSquaredLoss/RaggedToTensor_2/Shape:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/Users/mac/.conda/envs/machine_learning_learning/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/movie_len_model_12/RaggedTile/Reshape_3:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/movie_len_model_12/RaggedTile/Reshape_2:0\", shape=(None, 24), dtype=float32), dense_shape=Tensor(\"gradient_tape/movie_len_model_12/RaggedTile/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/Users/mac/.conda/envs/machine_learning_learning/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/movie_len_model_12/RaggedTile_1/Reshape_3:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/movie_len_model_12/RaggedTile_1/Reshape_2:0\", shape=(None, 24), dtype=float32), dense_shape=Tensor(\"gradient_tape/movie_len_model_12/RaggedTile_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 8s 8ms/step - loss: 11.7943 - ndcg_metric_5: 0.8066 - mrr_metric_5: 1.0000\n",
      "Epoch 2/4\n",
      "48/48 [==============================] - 4s 8ms/step - loss: 10.2762 - ndcg_metric_5: 0.8500 - mrr_metric_5: 1.0000\n",
      "Epoch 3/4\n",
      "48/48 [==============================] - 4s 7ms/step - loss: 3.4255 - ndcg_metric_5: 0.8693 - mrr_metric_5: 1.0000\n",
      "Epoch 4/4\n",
      "48/48 [==============================] - 5s 9ms/step - loss: 1.1635 - ndcg_metric_5: 0.8854 - mrr_metric_5: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff335b302b0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(ds_train, epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a709af33",
   "metadata": {},
   "source": [
    "## pairwise loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "433e2fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/.conda/envs/machine_learning_learning/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/PairwiseLogisticLoss/RaggedToTensor_2/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/PairwiseLogisticLoss/RaggedToTensor_2/boolean_mask/GatherV2:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/PairwiseLogisticLoss/RaggedToTensor_2/Shape:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/Users/mac/.conda/envs/machine_learning_learning/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/movie_len_model_14/RaggedTile/Reshape_3:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/movie_len_model_14/RaggedTile/Reshape_2:0\", shape=(None, 24), dtype=float32), dense_shape=Tensor(\"gradient_tape/movie_len_model_14/RaggedTile/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/Users/mac/.conda/envs/machine_learning_learning/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/movie_len_model_14/RaggedTile_1/Reshape_3:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/movie_len_model_14/RaggedTile_1/Reshape_2:0\", shape=(None, 24), dtype=float32), dense_shape=Tensor(\"gradient_tape/movie_len_model_14/RaggedTile_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 8s 9ms/step - loss: 14.5297 - ndcg_metric_7: 0.8081 - mrr_metric_7: 1.0000\n",
      "Epoch 2/4\n",
      "48/48 [==============================] - 5s 13ms/step - loss: 14.0157 - ndcg_metric_7: 0.9033 - mrr_metric_7: 1.0000\n",
      "Epoch 3/4\n",
      "48/48 [==============================] - 5s 12ms/step - loss: 11.7409 - ndcg_metric_7: 0.9173 - mrr_metric_7: 1.0000\n",
      "Epoch 4/4\n",
      "48/48 [==============================] - 5s 11ms/step - loss: 9.8551 - ndcg_metric_7: 0.9281 - mrr_metric_7: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff3245c8438>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = MovieLenModel(user_vocab=user_vocab, movie_vocab=movie_vocab)\n",
    "\n",
    "loss = tfr.keras.losses.PairwiseLogisticLoss(ragged=True)\n",
    "optimizor = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "metrics = [\n",
    "     tfr.keras.metrics.NDCGMetric(ragged=True)\n",
    "    , tfr.keras.metrics.MRRMetric(ragged=True)\n",
    "]\n",
    "\n",
    "model1.compile(loss=loss, optimizer=optimizor, metrics=metrics)\n",
    "model1.fit(ds_train, epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8327bd91",
   "metadata": {},
   "source": [
    "## listwise loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "baa889e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/.conda/envs/machine_learning_learning/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/ApproxNDCGLoss/RaggedToTensor_2/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/ApproxNDCGLoss/RaggedToTensor_2/boolean_mask/GatherV2:0\", shape=(None,), dtype=float32), dense_shape=Tensor(\"gradient_tape/ApproxNDCGLoss/RaggedToTensor_2/Shape:0\", shape=(1,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/Users/mac/.conda/envs/machine_learning_learning/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/movie_len_model_15/RaggedTile/Reshape_3:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/movie_len_model_15/RaggedTile/Reshape_2:0\", shape=(None, 24), dtype=float32), dense_shape=Tensor(\"gradient_tape/movie_len_model_15/RaggedTile/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/Users/mac/.conda/envs/machine_learning_learning/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/movie_len_model_15/RaggedTile_1/Reshape_3:0\", shape=(None,), dtype=int64), values=Tensor(\"gradient_tape/movie_len_model_15/RaggedTile_1/Reshape_2:0\", shape=(None, 24), dtype=float32), dense_shape=Tensor(\"gradient_tape/movie_len_model_15/RaggedTile_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 8s 8ms/step - loss: -0.6709 - ndcg_metric_8: 0.8111 - mrr_metric_8: 1.0000\n",
      "Epoch 2/4\n",
      "48/48 [==============================] - 5s 9ms/step - loss: -0.7207 - ndcg_metric_8: 0.9139 - mrr_metric_8: 1.0000\n",
      "Epoch 3/4\n",
      "48/48 [==============================] - 4s 8ms/step - loss: -0.8781 - ndcg_metric_8: 0.9203 - mrr_metric_8: 1.0000\n",
      "Epoch 4/4\n",
      "48/48 [==============================] - 5s 8ms/step - loss: -0.9145 - ndcg_metric_8: 0.9305 - mrr_metric_8: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff32438a5f8>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = MovieLenModel(user_vocab=user_vocab, movie_vocab=movie_vocab)\n",
    "\n",
    "loss = tfr.keras.losses.ApproxNDCGLoss(ragged=True)\n",
    "optimizor = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "metrics = [\n",
    "     tfr.keras.metrics.NDCGMetric(ragged=True)\n",
    "    , tfr.keras.metrics.MRRMetric(ragged=True)\n",
    "]\n",
    "\n",
    "model1.compile(loss=loss, optimizer=optimizor, metrics=metrics)\n",
    "model1.fit(ds_train, epochs=4)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python3.6(machine_learning_learning)",
   "language": "python",
   "name": "machine_learning_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
