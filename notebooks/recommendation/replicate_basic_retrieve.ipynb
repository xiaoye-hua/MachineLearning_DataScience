{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ff19d72",
   "metadata": {},
   "source": [
    "# Package "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "861126e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfd\n",
    "# import tensorflow_ranking as tfr\n",
    "import tensorflow_recommenders as tfrs\n",
    "from typing import Dict, Tuple, Text\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efd22df",
   "metadata": {},
   "source": [
    "# Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6ee7edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1517722",
   "metadata": {},
   "source": [
    "# Data process "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddb7d7d",
   "metadata": {},
   "source": [
    "## Raw data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6f232d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = tfd.load(name='movielens/100k-ratings', split='train')\n",
    "movies = tfd.load(name='movielens/100k-movies', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad871ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.map( lambda x: {\n",
    "    \"user_id\": x['user_id']\n",
    "    , 'movie_id': x['movie_id']\n",
    "#     , 'user_rating': x['user_rating']\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50cd3646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'user_id': b'138', 'movie_id': b'357'},\n",
       " {'user_id': b'92', 'movie_id': b'709'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ratings.take(2).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b5634bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'movie_genres': array([4]),\n",
       "  'movie_id': b'1681',\n",
       "  'movie_title': b'You So Crazy (1994)'},\n",
       " {'movie_genres': array([4, 7]),\n",
       "  'movie_id': b'1457',\n",
       "  'movie_title': b'Love Is All There Is (1996)'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(movies.take(2).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4581c32",
   "metadata": {},
   "source": [
    "## Id map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d56f69c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'1', b'10', b'100', b'1000', b'1001', b'1002', b'1003', b'1004',\n",
       "       b'1005', b'1006'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_ids = movies.map(lambda x: x['movie_id'])\n",
    "user_ids = ratings.map(lambda x: x['user_id'])\n",
    "\n",
    "\n",
    "movie_titles = movie_ids.batch(1_000)\n",
    "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
    "\n",
    "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
    "\n",
    "unique_movie_titles[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6676d540",
   "metadata": {},
   "source": [
    "## train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db1388e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_feature_label(x: Dict[str, tf.Tensor]) -> Tuple[Dict[str, tf.Tensor], tf.Tensor]:\n",
    "#     label = x.pop('user_rating')\n",
    "#     return x, label\n",
    "\n",
    "# ds_train = ds_train.map(lambda x: get_feature_label(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01c904b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "531e048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ratings.apply(\n",
    "    tf.data.experimental.dense_to_ragged_batch(batch_size=32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5817627a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'user_id': array([b'138', b'92', b'301', b'60', b'197', b'601', b'710', b'833',\n",
       "         b'916', b'940', b'611', b'707', b'699', b'16', b'314', b'217',\n",
       "         b'276', b'510', b'757', b'881', b'880', b'797', b'188', b'246',\n",
       "         b'445', b'91', b'372', b'891', b'71', b'279', b'688', b'59'],\n",
       "        dtype=object),\n",
       "  'movie_id': array([b'357', b'709', b'412', b'56', b'895', b'325', b'95', b'92',\n",
       "         b'425', b'271', b'355', b'712', b'825', b'240', b'1150', b'684',\n",
       "         b'124', b'294', b'265', b'465', b'823', b'243', b'392', b'202',\n",
       "         b'433', b'182', b'56', b'116', b'285', b'638', b'309', b'491'],\n",
       "        dtype=object)},\n",
       " {'user_id': array([b'56', b'854', b'615', b'639', b'699', b'195', b'676', b'279',\n",
       "         b'634', b'505', b'617', b'666', b'416', b'655', b'293', b'350',\n",
       "         b'404', b'28', b'428', b'733', b'354', b'486', b'409', b'582',\n",
       "         b'253', b'354', b'663', b'669', b'535', b'560', b'7', b'223'],\n",
       "        dtype=object),\n",
       "  'movie_id': array([b'117', b'466', b'160', b'19', b'591', b'99', b'302', b'1028',\n",
       "         b'124', b'125', b'7', b'98', b'794', b'927', b'248', b'136',\n",
       "         b'339', b'96', b'268', b'248', b'275', b'628', b'179', b'240',\n",
       "         b'200', b'516', b'1009', b'175', b'70', b'183', b'386', b'321'],\n",
       "        dtype=object)}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ds_train.take(2).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b65153",
   "metadata": {},
   "source": [
    "# Model Definition "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bdb946",
   "metadata": {},
   "source": [
    "## Old model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1228433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLenModel(tfrs.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        embedding_dimension = 24\n",
    "        self.user_embedding = tf.keras.Sequential([\n",
    "          tf.keras.layers.StringLookup(\n",
    "              vocabulary=unique_user_ids, mask_token=None),\n",
    "          # We add an additional embedding to account for unknown tokens.\n",
    "          tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "        ])\n",
    "        self.movie_embedding = tf.keras.Sequential([\n",
    "          tf.keras.layers.StringLookup(\n",
    "              vocabulary=unique_movie_titles, mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "        ])        \n",
    "        self.task= tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "            movie_ids.batch(128).map(self.movie_embedding)\n",
    "          )\n",
    "        )\n",
    "    \n",
    "    def compute_loss(self, features: Dict[str, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        user_emb = self.user_embedding(features['user_id'])\n",
    "        movie_emb =  self.movie_embedding(features['movie_id'])\n",
    "        print(f\"user: {user_emb.shape}\")\n",
    "        print(f\"movie: {movie_emb.shape}\")\n",
    "        return self.task(user_emb, movie_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dd9c2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# class MovielensModel(tfrs.Model):\n",
    "\n",
    "#   def __init__(self, user_vocab, movie_vocab):\n",
    "#     super().__init__()\n",
    "#     embedding_dimension = 32\n",
    "#     self.user_vocab = user_vocab\n",
    "#     self.movie_vocab = movie_vocab\n",
    "#     user_model = tf.keras.Sequential([\n",
    "# #       tf.keras.layers.StringLookup(\n",
    "# #           vocabulary=unique_user_ids, mask_token=None),\n",
    "#       # We add an additional embedding to account for unknown tokens.\n",
    "#       tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "#     ])\n",
    "#     movie_model = tf.keras.Sequential([\n",
    "# #       tf.keras.layers.StringLookup(\n",
    "# #           vocabulary=unique_movie_titles, mask_token=None),\n",
    "#       tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "#     ])\n",
    "#     metrics = tfrs.metrics.FactorizedTopK(\n",
    "#       candidates=movie_ids.batch(128).map(movie_model)\n",
    "#     )\n",
    "    \n",
    "#     task = tfrs.tasks.Retrieval(\n",
    "#       metrics=metrics\n",
    "#     )\n",
    "#     self.movie_model: tf.keras.Model = movie_model\n",
    "#     self.user_model: tf.keras.Model = user_model\n",
    "#     self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "#   def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "#     # We pick out the user features and pass them into the user model.\n",
    "#     user_embeddings = self.user_model(self.user_vocab(features[\"user_id\"]))\n",
    "#     # And pick out the movie features and pass them into the movie model,\n",
    "#     # getting embeddings back.\n",
    "#     positive_movie_embeddings = self.movie_model(self.movie_vocab(features[\"movie_id\"]))\n",
    "#     print(f\"user: {user_embeddings.shape}\")\n",
    "#     print(f\"movie: {positive_movie_embeddings.shape}\")\n",
    "#     # The task computes the loss and the metrics.\n",
    "#     return self.task(user_embeddings, positive_movie_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8d5f7d",
   "metadata": {},
   "source": [
    "## New model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06333a7b",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a4326d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: (None, 24)\n",
      "movie: (None, 24)\n",
      "user: (None, 24)\n",
      "movie: (None, 24)\n",
      "3125/3125 [==============================] - 242s 77ms/step - factorized_top_k/top_1_categorical_accuracy: 9.0000e-05 - factorized_top_k/top_5_categorical_accuracy: 0.0110 - factorized_top_k/top_10_categorical_accuracy: 0.0258 - factorized_top_k/top_50_categorical_accuracy: 0.1275 - factorized_top_k/top_100_categorical_accuracy: 0.2255 - loss: 105.7210 - regularization_loss: 0.0000e+00 - total_loss: 105.7210 14s - factorized_top_k/top_1_categori\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd3ad0d6da0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = MovieLenModel(\n",
    ")\n",
    "\n",
    "optimizor = tf.keras.optimizers.Adagrad(learning_rate=0.1)\n",
    "model1.compile(\n",
    "               optimizer=optimizor\n",
    "              )\n",
    "\n",
    "model1.fit(ds_train, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eea5cb3",
   "metadata": {},
   "source": [
    "# Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d76762f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fd3ad25d4a8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.user_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d683fb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model that takes in raw query features, and\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model1.user_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02fc0938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x7fd3ad4134a8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recommends movies out of the entire movies dataset.\n",
    "index.index_from_dataset(\n",
    "  tf.data.Dataset.zip((movie_ids.batch(100), movie_ids.batch(100).map(model1.movie_embedding)))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76689eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fc3a5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 42: [b'63' b'102' b'420' b'560' b'623']\n"
     ]
    }
   ],
   "source": [
    "# Get recommendations.\n",
    "scores, items = index(tf.constant([\"42\"]))\n",
    "print(f\"Recommendations for user 42: {titles[0, :5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce6478e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
       "array([[1.4527458, 1.4333963, 1.4160137, 1.4080179, 1.3786912, 1.3743391,\n",
       "        1.3707472, 1.3624487, 1.3570994, 1.3432596]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f153c4",
   "metadata": {},
   "source": [
    "##  Save and deploy -> accurate search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eddf05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = '../../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb819547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/60/6qphmx_d7x7_11vpj8524vf40000gn/T/tmpust1brl6/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/60/6qphmx_d7x7_11vpj8524vf40000gn/T/tmpust1brl6/model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: [b'63' b'102' b'420']\n",
      "tf.Tensor(\n",
      "[[1.4527458 1.4333963 1.4160137 1.4080179 1.3786912 1.3743391 1.3707472\n",
      "  1.3624487 1.3570994 1.3432596]], shape=(1, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Export the query model.\n",
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "    path = os.path.join(tmp, \"model\")\n",
    "\n",
    "    # Save the index.\n",
    "    tf.saved_model.save(index, path)\n",
    "\n",
    "    # Load it back; can also be done in TensorFlow Serving.\n",
    "    loaded = tf.saved_model.load(path)\n",
    "\n",
    "    # Pass a user id in, get top predicted movie titles back.\n",
    "    scores, titles = loaded([\"42\"])\n",
    "\n",
    "    print(f\"Recommendations: {titles[0][:3]}\")\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0842acfd",
   "metadata": {},
   "source": [
    "## Save & deploy -> approximate search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ad1ce82",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "The scann library is not present. Please install it using `pip install scann` to use the ScaNN layer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-12d8361cb888>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscann_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorized_top_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScaNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m scann_index.index_from_dataset(\n\u001b[1;32m      3\u001b[0m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovie_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovie_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m~/.conda/envs/machine_learning_learning/lib/python3.6/site-packages/tensorflow_recommenders/layers/factorized_top_k.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, query_model, k, distance_measure, num_leaves, num_leaves_to_search, dimensions_per_block, num_reordering_candidates, parallelize_batch_searches, name)\u001b[0m\n\u001b[1;32m    633\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_HAVE_SCANN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m       raise ImportError(\n\u001b[0;32m--> 635\u001b[0;31m           \u001b[0;34m\"The scann library is not present. Please install it using \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m           \"`pip install scann` to use the ScaNN layer.\")\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: The scann library is not present. Please install it using `pip install scann` to use the ScaNN layer."
     ]
    }
   ],
   "source": [
    "scann_index = tfrs.layers.factorized_top_k.ScaNN(model1.user_embedding)\n",
    "scann_index.index_from_dataset(\n",
    "  tf.data.Dataset.zip((movie_ids.batch(100), movie_ids.batch(100).map(model1.movie_embedding)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef94b19f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python3.6(machine_learning_learning)",
   "language": "python",
   "name": "machine_learning_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
