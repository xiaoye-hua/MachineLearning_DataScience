{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a22974e3",
   "metadata": {},
   "source": [
    "# Module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d440df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost                           1.5.2\r\n"
     ]
    }
   ],
   "source": [
    "! pip list | grep xg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7411b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# from __future__ import annotations\n",
    "from time import time\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfa4004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_cat_in_the_dat() -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"Assuming you have already downloaded the data into `input` directory.\"\"\"\n",
    "\n",
    "    df_train = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "    print(\n",
    "        \"train data set has got {} rows and {} columns\".format(\n",
    "            df_train.shape[0], df_train.shape[1]\n",
    "        )\n",
    "    )\n",
    "    X = df_train.drop([\"target\"], axis=1)\n",
    "    y = df_train[\"target\"]\n",
    "\n",
    "    for i in range(0, 5):\n",
    "        X[\"bin_\" + str(i)] = X[\"bin_\" + str(i)].astype(\"category\")\n",
    "\n",
    "    for i in range(0, 5):\n",
    "        X[\"nom_\" + str(i)] = X[\"nom_\" + str(i)].astype(\"category\")\n",
    "\n",
    "    for i in range(5, 10):\n",
    "        X[\"nom_\" + str(i)] = X[\"nom_\" + str(i)].apply(int, base=16)\n",
    "\n",
    "    for i in range(0, 6):\n",
    "        X[\"ord_\" + str(i)] = X[\"ord_\" + str(i)].astype(\"category\")\n",
    "\n",
    "    print(\n",
    "        \"train data set has got {} rows and {} columns\".format(X.shape[0], X.shape[1])\n",
    "    )\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36e2da2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"use_label_encoder\": False,\n",
    "    \"n_estimators\": 32,\n",
    "    \"colsample_bylevel\": 0.7,\n",
    "}\n",
    "\n",
    "\n",
    "def categorical_model(X: pd.DataFrame, y: pd.Series, output_dir: str) -> None:\n",
    "    \"\"\"Train using builtin categorical data support from XGBoost\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, random_state=1994, test_size=0.2\n",
    "    )\n",
    "    # Specify `enable_categorical` to True.\n",
    "    clf = xgb.XGBClassifier(\n",
    "        **params,\n",
    "        eval_metric=\"auc\",\n",
    "        enable_categorical=True,\n",
    "        max_cat_to_onehot=1,  # We use optimal partitioning exclusively\n",
    "    )\n",
    "    clf.fit(X_train, y_train, eval_set=[(X_test, y_test), (X_train, y_train)])\n",
    "    clf.save_model(os.path.join(output_dir, \"categorical.json\"))\n",
    "\n",
    "    y_score = clf.predict_proba(X_test)[:, 1]  # proba of positive samples\n",
    "    auc = roc_auc_score(y_test, y_score)\n",
    "    print(\"AUC of using builtin categorical data support:\", auc)\n",
    "\n",
    "\n",
    "def onehot_encoding_model(X: pd.DataFrame, y: pd.Series, output_dir: str) -> None:\n",
    "    \"\"\"Train using one-hot encoded data.\"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, random_state=42, test_size=0.2\n",
    "    )\n",
    "    # Specify `enable_categorical` to False as we are using encoded data.\n",
    "    clf = xgb.XGBClassifier(**params, eval_metric=\"auc\", enable_categorical=False)\n",
    "    clf.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_test, y_test), (X_train, y_train)],\n",
    "    )\n",
    "    clf.save_model(os.path.join(output_dir, \"one-hot.json\"))\n",
    "\n",
    "    y_score = clf.predict_proba(X_test)[:, 1]  # proba of positive samples\n",
    "    auc = roc_auc_score(y_test, y_score)\n",
    "    print(\"AUC of using onehot encoding:\", auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1243fb59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc6d2ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data set has got 300000 rows and 25 columns\n",
      "train data set has got 300000 rows and 24 columns\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float, bool or categorical.  When\n                categorical type is supplied, DMatrix parameter\n                `enable_categorical` must be set to `True`.bin_0, bin_1, bin_2, bin_3, bin_4, nom_0, nom_1, nom_2, nom_3, nom_4, ord_0, ord_1, ord_2, ord_3, ord_4, ord_5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-722ba93d71c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mTemporaryDirectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtmpdir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mcategorical_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmpdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Duration:categorical\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-8acd58061e39>\u001b[0m in \u001b[0;36mcategorical_model\u001b[0;34m(X, y, output_dir)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mmax_cat_to_onehot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# We use optimal partitioning exclusively\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     )\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"categorical.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/machine_learning_learning/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m                 \u001b[0mfeature_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_categorical\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m             )\n\u001b[0m\u001b[1;32m    423\u001b[0m             \u001b[0;31m# Stage the data, meta info are copied inside C++ MetaInfo.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_temporary_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_codes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/machine_learning_learning/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0miteration_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miteration_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m             \u001b[0mvalidate_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m         )\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/machine_learning_learning/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36m_wrap_evaluation_matrices\u001b[0;34m(self, X, y, group, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, eval_group, label_transform)\u001b[0m\n\u001b[1;32m    265\u001b[0m def _wrap_evaluation_matrices(\n\u001b[1;32m    266\u001b[0m     \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mgroup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/machine_learning_learning/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, enable_categorical)\u001b[0m\n\u001b[1;32m    503\u001b[0m             )\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/machine_learning_learning/lib/python3.6/site-packages/xgboost/data.py\u001b[0m in \u001b[0;36mdispatch_data_backend\u001b[0;34m(data, missing, threads, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0menable_categorical\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m                 \u001b[0mfeature_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCAT_T\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m                 \u001b[0mfeature_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pandas_dtype_mapper\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/machine_learning_learning/lib/python3.6/site-packages/xgboost/data.py\u001b[0m in \u001b[0;36m_from_pandas_df\u001b[0;34m(data, enable_categorical, missing, nthread, feature_names, feature_types)\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0menable_categorical\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mfeature_names\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m     \u001b[0mfeature_types\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m     \u001b[0mmeta\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0mmeta_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/machine_learning_learning/lib/python3.6/site-packages/xgboost/data.py\u001b[0m in \u001b[0;36m_transform_pandas_df\u001b[0;34m(data, enable_categorical, feature_names, feature_types, meta, meta_type)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;34m'int8'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;34m'int16'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0;34m'int32'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m     \u001b[0;34m'int64'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;34m'uint8'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float, bool or categorical.  When\n                categorical type is supplied, DMatrix parameter\n                `enable_categorical` must be set to `True`.bin_0, bin_1, bin_2, bin_3, bin_4, nom_0, nom_1, nom_2, nom_3, nom_4, ord_0, ord_1, ord_2, ord_3, ord_4, ord_5"
     ]
    }
   ],
   "source": [
    "X, y = load_cat_in_the_dat()\n",
    "\n",
    "with TemporaryDirectory() as tmpdir:\n",
    "    start = time()\n",
    "    categorical_model(X, y, tmpdir)\n",
    "    end = time()\n",
    "    print(\"Duration:categorical\", end - start)\n",
    "\n",
    "#     X = pd.get_dummies(X)\n",
    "#     start = time()\n",
    "#     onehot_encoding_model(X, y, tmpdir)\n",
    "#     end = time()\n",
    "#     print(\"Duration:onehot\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd346b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost                           1.5.2\r\n"
     ]
    }
   ],
   "source": [
    "! pip list | grep xg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4538be9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 240000 entries, 258467 to 191843\n",
      "Data columns (total 24 columns):\n",
      " #   Column  Non-Null Count   Dtype   \n",
      "---  ------  --------------   -----   \n",
      " 0   id      240000 non-null  int64   \n",
      " 1   bin_0   240000 non-null  category\n",
      " 2   bin_1   240000 non-null  category\n",
      " 3   bin_2   240000 non-null  category\n",
      " 4   bin_3   240000 non-null  category\n",
      " 5   bin_4   240000 non-null  category\n",
      " 6   nom_0   240000 non-null  category\n",
      " 7   nom_1   240000 non-null  category\n",
      " 8   nom_2   240000 non-null  category\n",
      " 9   nom_3   240000 non-null  category\n",
      " 10  nom_4   240000 non-null  category\n",
      " 11  nom_5   240000 non-null  int64   \n",
      " 12  nom_6   240000 non-null  int64   \n",
      " 13  nom_7   240000 non-null  int64   \n",
      " 14  nom_8   240000 non-null  int64   \n",
      " 15  nom_9   240000 non-null  int64   \n",
      " 16  ord_0   240000 non-null  category\n",
      " 17  ord_1   240000 non-null  category\n",
      " 18  ord_2   240000 non-null  category\n",
      " 19  ord_3   240000 non-null  category\n",
      " 20  ord_4   240000 non-null  category\n",
      " 21  ord_5   240000 non-null  category\n",
      " 22  day     240000 non-null  int64   \n",
      " 23  month   240000 non-null  int64   \n",
      "dtypes: category(16), int64(8)\n",
      "memory usage: 20.4 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71181a32",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float, bool or categorical.  When\n                categorical type is supplied, DMatrix parameter\n                `enable_categorical` must be set to `True`.bin_0, bin_1, bin_2, bin_3, bin_4, nom_0, nom_1, nom_2, nom_3, nom_4, ord_0, ord_1, ord_2, ord_3, ord_4, ord_5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-b5beb0060245>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/machine_learning_learning/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/machine_learning_learning/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0mfeature_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight_eval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight_eval_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m             eval_group=None, label_transform=label_transform)\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m         self._Booster = train(xgb_options, train_dmatrix,\n",
      "\u001b[0;32m~/.conda/envs/machine_learning_learning/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36m_wrap_evaluation_matrices\u001b[0;34m(self, X, y, group, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, eval_group, label_transform)\u001b[0m\n\u001b[1;32m    265\u001b[0m         train_dmatrix = DMatrix(data=X, label=y, weight=sample_weight,\n\u001b[1;32m    266\u001b[0m                                 \u001b[0mbase_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m                                 missing=self.missing, nthread=self.n_jobs)\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/machine_learning_learning/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, enable_categorical)\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0mfeature_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m             enable_categorical=enable_categorical)\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/machine_learning_learning/lib/python3.6/site-packages/xgboost/data.py\u001b[0m in \u001b[0;36mdispatch_data_backend\u001b[0;34m(data, missing, threads, feature_names, feature_types, enable_categorical)\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_pandas_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         return _from_pandas_df(data, enable_categorical, missing, threads,\n\u001b[0;32m--> 540\u001b[0;31m                                feature_names, feature_types)\n\u001b[0m\u001b[1;32m    541\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_pandas_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         return _from_pandas_series(data, missing, threads, feature_names,\n",
      "\u001b[0;32m~/.conda/envs/machine_learning_learning/lib/python3.6/site-packages/xgboost/data.py\u001b[0m in \u001b[0;36m_from_pandas_df\u001b[0;34m(data, enable_categorical, missing, nthread, feature_names, feature_types)\u001b[0m\n\u001b[1;32m    241\u001b[0m                     feature_names, feature_types):\n\u001b[1;32m    242\u001b[0m     data, feature_names, feature_types = _transform_pandas_df(\n\u001b[0;32m--> 243\u001b[0;31m         data, enable_categorical, feature_names, feature_types)\n\u001b[0m\u001b[1;32m    244\u001b[0m     return _from_numpy_array(data, missing, nthread, feature_names,\n\u001b[1;32m    245\u001b[0m                              feature_types)\n",
      "\u001b[0;32m~/.conda/envs/machine_learning_learning/lib/python3.6/site-packages/xgboost/data.py\u001b[0m in \u001b[0;36m_transform_pandas_df\u001b[0;34m(data, enable_categorical, feature_names, feature_types, meta, meta_type)\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0mcategorical\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0msupplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDMatrix\u001b[0m \u001b[0mparameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 `enable_categorical` must be set to `True`.\"\"\"\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmeta\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float, bool or categorical.  When\n                categorical type is supplied, DMatrix parameter\n                `enable_categorical` must be set to `True`.bin_0, bin_1, bin_2, bin_3, bin_4, nom_0, nom_1, nom_2, nom_3, nom_4, ord_0, ord_1, ord_2, ord_3, ord_4, ord_5"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train, eval_set=[(X_test, y_test), (X_train, y_train)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15b6d338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data set has got 300000 rows and 25 columns\n",
      "train data set has got 300000 rows and 24 columns\n",
      "[21:26:46] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { enable_categorical } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.65091\tvalidation_1-auc:0.65672\n",
      "[1]\tvalidation_0-auc:0.67295\tvalidation_1-auc:0.67806\n",
      "[2]\tvalidation_0-auc:0.67826\tvalidation_1-auc:0.68429\n",
      "[3]\tvalidation_0-auc:0.68405\tvalidation_1-auc:0.68979\n",
      "[4]\tvalidation_0-auc:0.69325\tvalidation_1-auc:0.69976\n",
      "[5]\tvalidation_0-auc:0.69648\tvalidation_1-auc:0.70385\n",
      "[6]\tvalidation_0-auc:0.70192\tvalidation_1-auc:0.70995\n",
      "[7]\tvalidation_0-auc:0.70513\tvalidation_1-auc:0.71402\n",
      "[8]\tvalidation_0-auc:0.70832\tvalidation_1-auc:0.71779\n",
      "[9]\tvalidation_0-auc:0.71200\tvalidation_1-auc:0.72267\n",
      "[10]\tvalidation_0-auc:0.71504\tvalidation_1-auc:0.72631\n",
      "[11]\tvalidation_0-auc:0.71743\tvalidation_1-auc:0.72945\n",
      "[12]\tvalidation_0-auc:0.71877\tvalidation_1-auc:0.73169\n",
      "[13]\tvalidation_0-auc:0.72098\tvalidation_1-auc:0.73439\n",
      "[14]\tvalidation_0-auc:0.72304\tvalidation_1-auc:0.73711\n",
      "[15]\tvalidation_0-auc:0.72419\tvalidation_1-auc:0.73915\n",
      "[16]\tvalidation_0-auc:0.72535\tvalidation_1-auc:0.74062\n",
      "[17]\tvalidation_0-auc:0.72686\tvalidation_1-auc:0.74272\n",
      "[18]\tvalidation_0-auc:0.72820\tvalidation_1-auc:0.74471\n",
      "[19]\tvalidation_0-auc:0.72934\tvalidation_1-auc:0.74656\n",
      "[20]\tvalidation_0-auc:0.73109\tvalidation_1-auc:0.74874\n",
      "[21]\tvalidation_0-auc:0.73235\tvalidation_1-auc:0.75041\n",
      "[22]\tvalidation_0-auc:0.73362\tvalidation_1-auc:0.75204\n",
      "[23]\tvalidation_0-auc:0.73442\tvalidation_1-auc:0.75335\n",
      "[24]\tvalidation_0-auc:0.73521\tvalidation_1-auc:0.75484\n",
      "[25]\tvalidation_0-auc:0.73607\tvalidation_1-auc:0.75625\n",
      "[26]\tvalidation_0-auc:0.73700\tvalidation_1-auc:0.75757\n",
      "[27]\tvalidation_0-auc:0.73766\tvalidation_1-auc:0.75863\n",
      "[28]\tvalidation_0-auc:0.73828\tvalidation_1-auc:0.75950\n",
      "[29]\tvalidation_0-auc:0.73883\tvalidation_1-auc:0.76068\n",
      "[30]\tvalidation_0-auc:0.73952\tvalidation_1-auc:0.76170\n",
      "[31]\tvalidation_0-auc:0.74036\tvalidation_1-auc:0.76290\n",
      "AUC of using onehot encoding: 0.7403633350438124\n",
      "Duration:onehot 7.753472089767456\n"
     ]
    }
   ],
   "source": [
    "X, y = load_cat_in_the_dat()\n",
    "\n",
    "with TemporaryDirectory() as tmpdir:\n",
    "#     start = time()\n",
    "#     categorical_model(X, y, tmpdir)\n",
    "#     end = time()\n",
    "#     print(\"Duration:categorical\", end - start)\n",
    "\n",
    "    X = pd.get_dummies(X)\n",
    "    start = time()\n",
    "    onehot_encoding_model(X, y, tmpdir)\n",
    "    end = time()\n",
    "    print(\"Duration:onehot\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fa8af1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python3.6(machine_learning_learning)",
   "language": "python",
   "name": "machine_learning_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
